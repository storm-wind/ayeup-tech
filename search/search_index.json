{"config":{"indexing":"full","lang":["en"],"min_search_length":3,"prebuild_index":true,"separator":"[\\s\\-]+"},"docs":[{"location":"","text":"Technical notes so I don't forget Some notes on how I got around some issues with my work within IT. Most of the notes on here I have curated from different forums and blogs etc. These solutions worked for my situation so they may not work for your situation as I found this to be the case with a lot fo solutions out there for different problems.","title":"Home"},{"location":"#technical-notes-so-i-dont-forget","text":"Some notes on how I got around some issues with my work within IT. Most of the notes on here I have curated from different forums and blogs etc. These solutions worked for my situation so they may not work for your situation as I found this to be the case with a lot fo solutions out there for different problems.","title":"Technical notes so I don't forget"},{"location":"linux/cron/","text":"Cron Jobs Schedule automatic jobs in Linux Layout minute hour day of month month day of week Valid entries * any value , value list separator - range of values / step values @yearly @annually @monthly @weekly @daily @hourly @reboot","title":"Cron"},{"location":"linux/cron/#cron-jobs","text":"Schedule automatic jobs in Linux","title":"Cron Jobs"},{"location":"linux/cron/#layout","text":"minute hour day of month month day of week","title":"Layout"},{"location":"linux/cron/#valid-entries","text":"* any value , value list separator - range of values / step values @yearly @annually @monthly @weekly @daily @hourly @reboot","title":"Valid entries"},{"location":"linux/docker/","text":"Docker Some stuff I came across while playing with docker. Stop a difficult container Sometimes some containers just won't stop or die when you tell them to, so you use this command and it seems to work. docker kill ----signal=SIGINT <container id> more info here https://www.ctl.io/developers/blog/post/gracefully-stopping-docker-containers/ Docker Commands Portainer Docker cmd docker run -d -p 9000:9000 --restart always --name portainer -v /<volume location>/portainer/data:/data -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce Handling Docker images Save a docker image ready to be deployed to another server. docker save -o <image-name>.tar <image-name> A breakdown of the command docker save -o <image-name> <commited image name> Deploy Docker image to server docker load -i <image-name.tar Docker Scripts Docker cleanup script This script deletes docker containers that haven't being running for a few days. #!/bin/bash # Script to clean up docker containers no longer running after a few days exec 2>&1 { /usr/bin/docker rm $(docker ps -a | grep -v Up\\ | grep '.*Exited\\ .*days\\ .*' | awk '{print $1}') } docker-compose Deploy multiple contianers in a stack using docker-compose, my preferred way of using docker. Firefly docker-compose example --- networks: firefly_iii_net: driver: bridge services: firefly_iii_app: image: jc5x/firefly-iii:latest depends_on: - firefly_iii_db networks: - firefly_iii_net ports: - \"8081:80\" env_file: .env volumes: - source: firefly_iii_export target: /var/www/firefly-iii/storage/export type: volume - source: firefly_iii_upload target: /var/www/firefly-iii/storage/upload type: volume firefly_iii_db: image: \"postgres:10\" environment: - POSTGRES_PASSWORD=secret - POSTGRES_USER=firefly networks: - firefly_iii_net volumes: - firefly_iii_db:/var/lib/postgresql/data version: \"3.2\" volumes: firefly_iii_db: ~ firefly_iii_export: ~ firefly_iii_upload: ~","title":"Docker"},{"location":"linux/docker/#docker","text":"Some stuff I came across while playing with docker.","title":"Docker"},{"location":"linux/docker/#stop-a-difficult-container","text":"Sometimes some containers just won't stop or die when you tell them to, so you use this command and it seems to work. docker kill ----signal=SIGINT <container id> more info here https://www.ctl.io/developers/blog/post/gracefully-stopping-docker-containers/","title":"Stop a difficult container"},{"location":"linux/docker/#docker-commands","text":"","title":"Docker Commands"},{"location":"linux/docker/#portainer-docker-cmd","text":"docker run -d -p 9000:9000 --restart always --name portainer -v /<volume location>/portainer/data:/data -v /var/run/docker.sock:/var/run/docker.sock portainer/portainer-ce","title":"Portainer Docker cmd"},{"location":"linux/docker/#handling-docker-images","text":"Save a docker image ready to be deployed to another server. docker save -o <image-name>.tar <image-name> A breakdown of the command docker save -o <image-name> <commited image name>","title":"Handling Docker images"},{"location":"linux/docker/#deploy-docker-image-to-server","text":"docker load -i <image-name.tar","title":"Deploy Docker image to server"},{"location":"linux/docker/#docker-scripts","text":"","title":"Docker Scripts"},{"location":"linux/docker/#docker-cleanup-script","text":"This script deletes docker containers that haven't being running for a few days. #!/bin/bash # Script to clean up docker containers no longer running after a few days exec 2>&1 { /usr/bin/docker rm $(docker ps -a | grep -v Up\\ | grep '.*Exited\\ .*days\\ .*' | awk '{print $1}') }","title":"Docker cleanup script"},{"location":"linux/docker/#docker-compose","text":"Deploy multiple contianers in a stack using docker-compose, my preferred way of using docker.","title":"docker-compose"},{"location":"linux/docker/#firefly-docker-compose-example","text":"--- networks: firefly_iii_net: driver: bridge services: firefly_iii_app: image: jc5x/firefly-iii:latest depends_on: - firefly_iii_db networks: - firefly_iii_net ports: - \"8081:80\" env_file: .env volumes: - source: firefly_iii_export target: /var/www/firefly-iii/storage/export type: volume - source: firefly_iii_upload target: /var/www/firefly-iii/storage/upload type: volume firefly_iii_db: image: \"postgres:10\" environment: - POSTGRES_PASSWORD=secret - POSTGRES_USER=firefly networks: - firefly_iii_net volumes: - firefly_iii_db:/var/lib/postgresql/data version: \"3.2\" volumes: firefly_iii_db: ~ firefly_iii_export: ~ firefly_iii_upload: ~","title":"Firefly docker-compose example"},{"location":"linux/logrotate/","text":"Logrotate usage A linux tool to rotate logs automatically so as not to use up all disk spac. Pretty handy. Setup logrotate Run logroate manually For verbose add -v like example below. logrotate -v -f /etc/logrotate.d/httpd Example of logrotate /var/log/httpd/*log { size 200M compress missingok notifempty sharedscripts delaycompress postrotate /bin/systemctl reload httpd.service > /dev/null 2>/dev/null || true endscript } Letsbreak it down. So /var/log/httpd/*log is the location of log file/s. size 200M is size of log file gets before being rotated. compress is basically zipping up the file when rotated. missingok notifempty sharedscripts delaycompress means to compress file on next log rotation. postrotate self explainatory.","title":"Logrotate"},{"location":"linux/logrotate/#logrotate-usage","text":"A linux tool to rotate logs automatically so as not to use up all disk spac. Pretty handy.","title":"Logrotate usage"},{"location":"linux/logrotate/#setup-logrotate","text":"","title":"Setup logrotate"},{"location":"linux/logrotate/#run-logroate-manually","text":"For verbose add -v like example below. logrotate -v -f /etc/logrotate.d/httpd","title":"Run logroate manually"},{"location":"linux/logrotate/#example-of-logrotate","text":"/var/log/httpd/*log { size 200M compress missingok notifempty sharedscripts delaycompress postrotate /bin/systemctl reload httpd.service > /dev/null 2>/dev/null || true endscript } Letsbreak it down. So /var/log/httpd/*log is the location of log file/s. size 200M is size of log file gets before being rotated. compress is basically zipping up the file when rotated. missingok notifempty sharedscripts delaycompress means to compress file on next log rotation. postrotate self explainatory.","title":"Example of logrotate"},{"location":"linux/lvm/","text":"How to use LVM LVM is used to manage disk capacity with Linux. Expand an existing LVM This assumes you have added an extra disk on VMware to the VM affected. echo \"- - -\" > /sys/class/scsi_host/scan0 lsblk fdisk /dev/sdd pvcreate /dev/sdd1 vgs vgextend centos /dev/sdd1 vgs pvscan lvextend -l +100%FREE /dev/centos/var or for specifc sizes, lvextend -L <+size> <Logical volume name path> xfs_growfs /dev/mapper/centos-var Expand partition for active partition How to expand a live partition. This example uses /dev/sda2 fdisk /dev/sda You will get something like this below, Command (m for help): p Disk /dev/sda: 68.7 GB, 68719476736 bytes, 134217728 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000bffd8 Device Boot Start End Blocks Id System /dev/sda1 * 2048 1050623 524288 83 Linux /dev/sda2 1050624 36716543 17832960 8e Linux LVM So you have checked which one is which, now we delete the partition /dev/sda2 . Command (m for help): d Partition number (1,2, default 2): 2 Partition 2 is deleted Now we create a new partion with a new end block. Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (1050624-134217727, default 1050624): 1050624 Last sector, +sectors or +size{K,M,G} (1050624-134217727, default 134217727): 73433086 Partition 2 of type Linux and of size 34.5 GiB is set Lets check what is now existing Command (m for help): p Disk /dev/sda: 68.7 GB, 68719476736 bytes, 134217728 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000bffd8 Device Boot Start End Blocks Id System /dev/sda1 * 2048 1050623 524288 83 Linux /dev/sda2 1050624 73433086 36191231+ 83 Linux Also, change partition type, using option t and code 8e to change to Linux LVM . Command (m for help): wq The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks. Then run the following partprobe partx -u /dev/sda cat /proc/partitions | grep sda 8 0 67108864 sda 8 1 524288 sda1 8 2 36191231 sda2 Now run pvresize /dev/sda2 You'll get this below Physical volume \"/dev/sda2\" changed 1 physical volume(s) resized or updated / 0 physical volume(s) not resized Now run pvs PV VG Fmt Attr PSize PFree /dev/sda2 rhel lvm2 a-- 34.51g 17.51g","title":"LVM"},{"location":"linux/lvm/#how-to-use-lvm","text":"LVM is used to manage disk capacity with Linux.","title":"How to use LVM"},{"location":"linux/lvm/#expand-an-existing-lvm","text":"This assumes you have added an extra disk on VMware to the VM affected. echo \"- - -\" > /sys/class/scsi_host/scan0 lsblk fdisk /dev/sdd pvcreate /dev/sdd1 vgs vgextend centos /dev/sdd1 vgs pvscan lvextend -l +100%FREE /dev/centos/var or for specifc sizes, lvextend -L <+size> <Logical volume name path> xfs_growfs /dev/mapper/centos-var","title":"Expand an existing LVM"},{"location":"linux/lvm/#expand-partition-for-active-partition","text":"How to expand a live partition. This example uses /dev/sda2 fdisk /dev/sda You will get something like this below, Command (m for help): p Disk /dev/sda: 68.7 GB, 68719476736 bytes, 134217728 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000bffd8 Device Boot Start End Blocks Id System /dev/sda1 * 2048 1050623 524288 83 Linux /dev/sda2 1050624 36716543 17832960 8e Linux LVM So you have checked which one is which, now we delete the partition /dev/sda2 . Command (m for help): d Partition number (1,2, default 2): 2 Partition 2 is deleted Now we create a new partion with a new end block. Command (m for help): n Partition type: p primary (1 primary, 0 extended, 3 free) e extended Select (default p): p Partition number (2-4, default 2): First sector (1050624-134217727, default 1050624): 1050624 Last sector, +sectors or +size{K,M,G} (1050624-134217727, default 134217727): 73433086 Partition 2 of type Linux and of size 34.5 GiB is set Lets check what is now existing Command (m for help): p Disk /dev/sda: 68.7 GB, 68719476736 bytes, 134217728 sectors Units = sectors of 1 * 512 = 512 bytes Sector size (logical/physical): 512 bytes / 512 bytes I/O size (minimum/optimal): 512 bytes / 512 bytes Disk label type: dos Disk identifier: 0x000bffd8 Device Boot Start End Blocks Id System /dev/sda1 * 2048 1050623 524288 83 Linux /dev/sda2 1050624 73433086 36191231+ 83 Linux Also, change partition type, using option t and code 8e to change to Linux LVM . Command (m for help): wq The partition table has been altered! Calling ioctl() to re-read partition table. WARNING: Re-reading the partition table failed with error 16: Device or resource busy. The kernel still uses the old table. The new table will be used at the next reboot or after you run partprobe(8) or kpartx(8) Syncing disks. Then run the following partprobe partx -u /dev/sda cat /proc/partitions | grep sda 8 0 67108864 sda 8 1 524288 sda1 8 2 36191231 sda2 Now run pvresize /dev/sda2 You'll get this below Physical volume \"/dev/sda2\" changed 1 physical volume(s) resized or updated / 0 physical volume(s) not resized Now run pvs PV VG Fmt Attr PSize PFree /dev/sda2 rhel lvm2 a-- 34.51g 17.51g","title":"Expand partition for active partition"},{"location":"linux/podman/","text":"Podman Podman is Redhats answer to Docker. You can un docker continaers as a systemd service. Bind podman container to local directory sudo podman run -it -p 80:80 --name nginx-proxy -v /opt/podman/nginx/conf.d:/etc/nginx/conf.d nginx sh","title":"Podman"},{"location":"linux/podman/#podman","text":"Podman is Redhats answer to Docker. You can un docker continaers as a systemd service.","title":"Podman"},{"location":"linux/podman/#bind-podman-container-to-local-directory","text":"sudo podman run -it -p 80:80 --name nginx-proxy -v /opt/podman/nginx/conf.d:/etc/nginx/conf.d nginx sh","title":"Bind podman container to local directory"},{"location":"linux/proxmox/","text":"ProxMox Initial setup Disable Commercial Repo sed -i \"s/^deb/\\#deb/\" /etc/apt/sources.list.d/pve-enterprise.list apt-get update Add PVE Community Repo echo \"deb http://download.proxmox.com/debian/pve $(grep \"VERSION=\" /etc/os-release | sed -n 's/.*(\\(.*\\)).*/\\1/p') pve-no-subscription\" > /etc/apt/sources.list.d/pve-no-enterprise.list apt-get update Remove nag echo \"DPkg::Post-Invoke { \\\"dpkg -V proxmox-widget-toolkit | grep -q '/proxmoxlib\\.js$'; if [ \\$? -eq 1 ]; then { echo 'Removing subscription nag from UI...'; sed -i '/data.status/{s/\\!//;s/Active/NoMoreNagging/}' /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js; }; fi\\\"; };\" > /etc/apt/apt.conf.d/no-nag-script apt --reinstall install proxmox-widget-toolkit Install qemu agent apt-get install -y qemu-guest-agent systemctl enable qemu-guest-agent systemctl start qemu-guest-agent LXC Containers on Proxmox LXC containers are containers much like Docker but unlike docker have their own namespaces and utilise the host system kernel. I use LXC for a variety of purposes. Mainly for services I want to isolate and have several dependencies around it. For example, Pi-Hole or a reverse proxy. These can be run from Docker as well but I like the fact I can manage these LXC containers through Proxmox UI. Anyway, some caveats I found when creating LXC containers. SSH is not enabled by default space on filesystem to create SSH session doesn't work. So heres what you do. systemctl start sshd mkdir /run/sshd Thats it.","title":"Proxmox"},{"location":"linux/proxmox/#proxmox-initial-setup","text":"","title":"ProxMox Initial setup"},{"location":"linux/proxmox/#disable-commercial-repo","text":"sed -i \"s/^deb/\\#deb/\" /etc/apt/sources.list.d/pve-enterprise.list apt-get update","title":"Disable Commercial Repo"},{"location":"linux/proxmox/#add-pve-community-repo","text":"echo \"deb http://download.proxmox.com/debian/pve $(grep \"VERSION=\" /etc/os-release | sed -n 's/.*(\\(.*\\)).*/\\1/p') pve-no-subscription\" > /etc/apt/sources.list.d/pve-no-enterprise.list apt-get update","title":"Add PVE Community Repo"},{"location":"linux/proxmox/#remove-nag","text":"echo \"DPkg::Post-Invoke { \\\"dpkg -V proxmox-widget-toolkit | grep -q '/proxmoxlib\\.js$'; if [ \\$? -eq 1 ]; then { echo 'Removing subscription nag from UI...'; sed -i '/data.status/{s/\\!//;s/Active/NoMoreNagging/}' /usr/share/javascript/proxmox-widget-toolkit/proxmoxlib.js; }; fi\\\"; };\" > /etc/apt/apt.conf.d/no-nag-script apt --reinstall install proxmox-widget-toolkit","title":"Remove nag"},{"location":"linux/proxmox/#install-qemu-agent","text":"apt-get install -y qemu-guest-agent systemctl enable qemu-guest-agent systemctl start qemu-guest-agent","title":"Install qemu agent"},{"location":"linux/proxmox/#lxc-containers-on-proxmox","text":"LXC containers are containers much like Docker but unlike docker have their own namespaces and utilise the host system kernel. I use LXC for a variety of purposes. Mainly for services I want to isolate and have several dependencies around it. For example, Pi-Hole or a reverse proxy. These can be run from Docker as well but I like the fact I can manage these LXC containers through Proxmox UI. Anyway, some caveats I found when creating LXC containers. SSH is not enabled by default space on filesystem to create SSH session doesn't work. So heres what you do. systemctl start sshd mkdir /run/sshd Thats it.","title":"LXC Containers on Proxmox"},{"location":"networks/haproxy/","text":"HAProxy Haproxy is a kick ass proxy which is scalable and has a multitude of uses. HAProxy Example An example config of HAProxy that is a tcp pass through. #--------------------------------------------------------------------- # Example configuration for a possible web application. See the # full configuration options online. # # https://www.haproxy.org/download/1.8/doc/configuration.txt # #--------------------------------------------------------------------- #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the '-r' option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats # utilize system-wide crypto-policies ssl-default-bind-ciphers PROFILE=SYSTEM ssl-default-server-ciphers PROFILE=SYSTEM #--------------------------------------------------------------------- # common defaults that all the 'listen' and 'backend' sections will # use if not designated in their block #--------------------------------------------------------------------- defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 #--------------------------------------------------------------------- # main frontend which proxys to the backends #--------------------------------------------------------------------- #frontend main # bind *:5000 # acl url_static path_beg -i /static /images /javascript /stylesheets # acl url_static path_end -i .jpg .gif .png .css .js # use_backend static if url_static # default_backend app frontend https_in mode tcp option tcplog bind *:443 acl tls req.ssl_hello_type 1 tcp-request inspect-delay 5s tcp-request content accept if tls acl <server1> req.ssl_sni -i <sub domain name> acl <server1> req.ssl_sni -i <sub domain name> acl <server2> req.ssl_sni -i <sub domain name> acl <server2> req.ssl_sni -i <sub domain name> use_backend <server1> if <server1> use_backend <server2> if <server2> #--------------------------------------------------------------------- # static backend for serving up images, stylesheets and such #--------------------------------------------------------------------- #backend static # balance roundrobin # server static 127.0.0.1:4331 check backend <server1> mode tcp option tcplog option ssl-hello-chk server <server1> <ip address of backend server>:<port> backend <server2> mode tcp option tcplog option ssl-hello-chk server <server2> <ip address of backend server>:<port> #--------------------------------------------------------------------- # round robin balancing between the various backends #--------------------------------------------------------------------- #backend app # balance roundrobin # server app1 127.0.0.1:5001 check # server app2 127.0.0.1:5002 check # server app3 127.0.0.1:5003 check # server app4 127.0.0.1:5004 check The Stats Section This is a stats page you can login to, to view the HAProxy stats. mode http bind <ip address of host>:<port> # ssl crt /etc/ssl/<cert chain - pem format> stats enable stats show-legends stats hide-version stats realm Haproxy\\ Statistics stats uri /stats stats refresh 5s stats auth <username>:<password> Another example Here is an example of frontends listening on different ports and implementing STunnel to enccrpt traffic.","title":"HAProxy"},{"location":"networks/haproxy/#haproxy","text":"Haproxy is a kick ass proxy which is scalable and has a multitude of uses.","title":"HAProxy"},{"location":"networks/haproxy/#haproxy-example","text":"An example config of HAProxy that is a tcp pass through. #--------------------------------------------------------------------- # Example configuration for a possible web application. See the # full configuration options online. # # https://www.haproxy.org/download/1.8/doc/configuration.txt # #--------------------------------------------------------------------- #--------------------------------------------------------------------- # Global settings #--------------------------------------------------------------------- global # to have these messages end up in /var/log/haproxy.log you will # need to: # # 1) configure syslog to accept network log events. This is done # by adding the '-r' option to the SYSLOGD_OPTIONS in # /etc/sysconfig/syslog # # 2) configure local2 events to go to the /var/log/haproxy.log # file. A line like the following can be added to # /etc/sysconfig/syslog # # local2.* /var/log/haproxy.log # log 127.0.0.1 local2 chroot /var/lib/haproxy pidfile /var/run/haproxy.pid maxconn 4000 user haproxy group haproxy daemon # turn on stats unix socket stats socket /var/lib/haproxy/stats # utilize system-wide crypto-policies ssl-default-bind-ciphers PROFILE=SYSTEM ssl-default-server-ciphers PROFILE=SYSTEM #--------------------------------------------------------------------- # common defaults that all the 'listen' and 'backend' sections will # use if not designated in their block #--------------------------------------------------------------------- defaults mode http log global option httplog option dontlognull option http-server-close option forwardfor except 127.0.0.0/8 option redispatch retries 3 timeout http-request 10s timeout queue 1m timeout connect 10s timeout client 1m timeout server 1m timeout http-keep-alive 10s timeout check 10s maxconn 3000 #--------------------------------------------------------------------- # main frontend which proxys to the backends #--------------------------------------------------------------------- #frontend main # bind *:5000 # acl url_static path_beg -i /static /images /javascript /stylesheets # acl url_static path_end -i .jpg .gif .png .css .js # use_backend static if url_static # default_backend app frontend https_in mode tcp option tcplog bind *:443 acl tls req.ssl_hello_type 1 tcp-request inspect-delay 5s tcp-request content accept if tls acl <server1> req.ssl_sni -i <sub domain name> acl <server1> req.ssl_sni -i <sub domain name> acl <server2> req.ssl_sni -i <sub domain name> acl <server2> req.ssl_sni -i <sub domain name> use_backend <server1> if <server1> use_backend <server2> if <server2> #--------------------------------------------------------------------- # static backend for serving up images, stylesheets and such #--------------------------------------------------------------------- #backend static # balance roundrobin # server static 127.0.0.1:4331 check backend <server1> mode tcp option tcplog option ssl-hello-chk server <server1> <ip address of backend server>:<port> backend <server2> mode tcp option tcplog option ssl-hello-chk server <server2> <ip address of backend server>:<port> #--------------------------------------------------------------------- # round robin balancing between the various backends #--------------------------------------------------------------------- #backend app # balance roundrobin # server app1 127.0.0.1:5001 check # server app2 127.0.0.1:5002 check # server app3 127.0.0.1:5003 check # server app4 127.0.0.1:5004 check","title":"HAProxy Example"},{"location":"networks/haproxy/#the-stats-section","text":"This is a stats page you can login to, to view the HAProxy stats. mode http bind <ip address of host>:<port> # ssl crt /etc/ssl/<cert chain - pem format> stats enable stats show-legends stats hide-version stats realm Haproxy\\ Statistics stats uri /stats stats refresh 5s stats auth <username>:<password>","title":"The Stats Section"},{"location":"networks/haproxy/#another-example","text":"Here is an example of frontends listening on different ports and implementing STunnel to enccrpt traffic.","title":"Another example"},{"location":"networks/stunnel/","text":"Stunnel Stunnel is a free linux program to encrypt traffic for any application that does not have encrypted traffic. You basically redirect that applications traffic to the Stunnel port and it will encrypt it across the network. Config Here is an example configuration. /etc/stunnel/stunnel.conf cert = /etc/pki/tls/certs/stunnel.pem ; Allow only TLS, thus avoiding SSL #sslVersion = all options = NO_SSLv2 chroot = /var/lib/stunnel setuid = nobody setgid = nobody pid = /stunnel.pid socket = l:TCP_NODELAY=1 socket = r:TCP_NODELAY=1 #foreground = no client = yes debug = 7 output = /log/stunnel.log [<name of app to encrypt, ie metricbeat>] accept = localhost:5220 connect = <ip address of destination>:<port number> TIMEOUTclose = 0 verify = 0 This is slightly different to the standard config as its in /var/lib/stunnel not /var/run/stunnel . This is to get around the issue when server reboots the /var/run/stunnel * chroot gets wiped.","title":"Stunnel"},{"location":"networks/stunnel/#stunnel","text":"Stunnel is a free linux program to encrypt traffic for any application that does not have encrypted traffic. You basically redirect that applications traffic to the Stunnel port and it will encrypt it across the network.","title":"Stunnel"},{"location":"networks/stunnel/#config","text":"Here is an example configuration. /etc/stunnel/stunnel.conf cert = /etc/pki/tls/certs/stunnel.pem ; Allow only TLS, thus avoiding SSL #sslVersion = all options = NO_SSLv2 chroot = /var/lib/stunnel setuid = nobody setgid = nobody pid = /stunnel.pid socket = l:TCP_NODELAY=1 socket = r:TCP_NODELAY=1 #foreground = no client = yes debug = 7 output = /log/stunnel.log [<name of app to encrypt, ie metricbeat>] accept = localhost:5220 connect = <ip address of destination>:<port number> TIMEOUTclose = 0 verify = 0 This is slightly different to the standard config as its in /var/lib/stunnel not /var/run/stunnel . This is to get around the issue when server reboots the /var/run/stunnel * chroot gets wiped.","title":"Config"},{"location":"networks/zerotier/","text":"How to install Zerotier Basic install curl -s https://install.zerotier.com | sudo bash More secure curl -s 'https://raw.githubusercontent.com/zerotier/ZeroTierOne/master/doc/contact%40zerotier.com.gpg' | gpg --import && \\ if z=$(curl -s 'https://install.zerotier.com/' | gpg); then echo \"$z\" | sudo bash; fi To Join a network From the command line simply type zerotier-cli join ################ with ############### being the 16-digit network ID of the network you wish to join.","title":"Zerotier"},{"location":"networks/zerotier/#how-to-install-zerotier","text":"Basic install curl -s https://install.zerotier.com | sudo bash More secure curl -s 'https://raw.githubusercontent.com/zerotier/ZeroTierOne/master/doc/contact%40zerotier.com.gpg' | gpg --import && \\ if z=$(curl -s 'https://install.zerotier.com/' | gpg); then echo \"$z\" | sudo bash; fi To Join a network From the command line simply type zerotier-cli join ################ with ############### being the 16-digit network ID of the network you wish to join.","title":"How to install Zerotier"},{"location":"platforms/argo/","text":"Argo Tunnels This is a service from Cloudflare where you can set an outbound port and reach out to the Cloudflare CDN and create secure tunnels while not exposing your server to the web. Setup Cloudflared as a Service You have to make sure that /root/.cloudflared/config.yml is valid. Here is an example, hostname: <servername> credentials-file: /root/.cloudflared/<uuid for tunnel>.json tunnel: <tunnel name> ingress: # Rules map traffic from a hostname to a local service: - hostname: <yourdomain.com> service: https://localhost:<port listening on> - hostname: <anotherdoamin.com> service: https://<another server IP or port> When you run cloudflared service install it will pull the config and copy into /etc/cloudflared if its not valid then the systemd install won't work. Three files are generated in /etc/systemd/system which are, cloudflared.service cloudflared-update.service cloudflared-update.timer cloudflared.service [Unit] Description=Argo Tunnel After=network.target [Service] Ports Make sure 7844 and 443 are opened up. 7844 is used for the Argo traffic itself. 443 is used to update the cloudflared binary and for API calls to make sure the tunnels are up and connected.","title":"Argo"},{"location":"platforms/argo/#argo-tunnels","text":"This is a service from Cloudflare where you can set an outbound port and reach out to the Cloudflare CDN and create secure tunnels while not exposing your server to the web.","title":"Argo Tunnels"},{"location":"platforms/argo/#setup-cloudflared-as-a-service","text":"You have to make sure that /root/.cloudflared/config.yml is valid. Here is an example, hostname: <servername> credentials-file: /root/.cloudflared/<uuid for tunnel>.json tunnel: <tunnel name> ingress: # Rules map traffic from a hostname to a local service: - hostname: <yourdomain.com> service: https://localhost:<port listening on> - hostname: <anotherdoamin.com> service: https://<another server IP or port> When you run cloudflared service install it will pull the config and copy into /etc/cloudflared if its not valid then the systemd install won't work. Three files are generated in /etc/systemd/system which are, cloudflared.service cloudflared-update.service cloudflared-update.timer","title":"Setup Cloudflared as a Service"},{"location":"platforms/argo/#cloudflaredservice","text":"[Unit] Description=Argo Tunnel After=network.target [Service]","title":"cloudflared.service"},{"location":"platforms/argo/#ports","text":"Make sure 7844 and 443 are opened up. 7844 is used for the Argo traffic itself. 443 is used to update the cloudflared binary and for API calls to make sure the tunnels are up and connected.","title":"Ports"},{"location":"platforms/awscli/","text":"How to Update to a newer version curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip ./aws/install which aws ls -l /usr/local/bin/aws ./aws/install --bin-dir /usr/bin --install-dir /usr/bin/aws-cli --update If old version hangs around, look for the aws binary and then do the following and confirm the binary version find / -name aws /usr/bin/aws --version rm -f /usr/bin/aws ./aws/install --bin-dir /usr/bin --install-dir /usr/bin/aws-cli --update Job done so when you run aws --version it should return the correct version. Switch between AWS CLI Profiles To switch between profiles you can add --profile <profile name> Or just export AWS_PROFILE=<profile name> for multiple commands.","title":"AWS CLI"},{"location":"platforms/awscli/#how-to-update-to-a-newer-version","text":"curl \"https://awscli.amazonaws.com/awscli-exe-linux-x86_64.zip\" -o \"awscliv2.zip\" unzip awscliv2.zip ./aws/install which aws ls -l /usr/local/bin/aws ./aws/install --bin-dir /usr/bin --install-dir /usr/bin/aws-cli --update If old version hangs around, look for the aws binary and then do the following and confirm the binary version find / -name aws /usr/bin/aws --version rm -f /usr/bin/aws ./aws/install --bin-dir /usr/bin --install-dir /usr/bin/aws-cli --update Job done so when you run aws --version it should return the correct version.","title":"How to Update to a newer version"},{"location":"platforms/awscli/#switch-between-aws-cli-profiles","text":"To switch between profiles you can add --profile <profile name> Or just export AWS_PROFILE=<profile name> for multiple commands.","title":"Switch between AWS CLI Profiles"},{"location":"platforms/vmware/","text":"Most common CLI commands for VMWare ESXi. Use SSH or esxi shells. vim-cmd vmsvc/getallvms List all VMs running on the host. Also provides vmid, required for commands below. vim-cmd vmsvc/power.off vmid Power off specified VM. vim-cmd vmsvc/power.on vmid Power off specified VM. vim-cmd vmsvc/power.reboot vmid Reboot specified VM. vim-cmd solo/registervm /vmfs/volume/datastore/subdir/vm-file.vmx Register the VM stored at location on the ESX host inventory. vim-cmd vmsvc/unregister vmid Unregister VM from the host. Does not remove the VM's files from the datastore. vim-cmd vmsvc/destroy vmid Delete the specified VM. The VMDK and VMX files will be deleted from storage as well. vim-cmd vmsvc/tools.install vmid Initiates an installation of VMWare Tools on the VM vim-cmd hostsvc/maintenance_mode_enter Put the host into maintenance mode. vim-cmd hostsvc/maintenance_mode_exit Take the host out of maintenance mode. vim-cmd hostsvc/net/info Show networking information of the host. chkconfig -l Show services running on the host. Can also be used to change startup configuration. esxtop Display list of processes and its usage of resources. Works similar to linux top. esxcfg-info Show host's configuration and information. esxcfg-nics -l Show current NIC configuration. esxcfg-vswitch -l Show current vSwitch configuration. vmkerrcode -l Display a reference list of VMKernel return codes and descriptions. dcui Start the console UI (when accessing through SSH). vsish Run the VMWare Interactive Shell (from SSH). decodeSel /var/log/ipmi_sel.raw Read IPMI system log of physical server. Replace vmid with the value you retrieved from the getallvms command (first one in the table).Replace path with the full path and file name of a VMX-file (= configuration file of a VM).","title":"VMware"},{"location":"platforms/vmware/#most-common-cli-commands-for-vmware-esxi","text":"Use SSH or esxi shells. vim-cmd vmsvc/getallvms List all VMs running on the host. Also provides vmid, required for commands below. vim-cmd vmsvc/power.off vmid Power off specified VM. vim-cmd vmsvc/power.on vmid Power off specified VM. vim-cmd vmsvc/power.reboot vmid Reboot specified VM. vim-cmd solo/registervm /vmfs/volume/datastore/subdir/vm-file.vmx Register the VM stored at location on the ESX host inventory. vim-cmd vmsvc/unregister vmid Unregister VM from the host. Does not remove the VM's files from the datastore. vim-cmd vmsvc/destroy vmid Delete the specified VM. The VMDK and VMX files will be deleted from storage as well. vim-cmd vmsvc/tools.install vmid Initiates an installation of VMWare Tools on the VM vim-cmd hostsvc/maintenance_mode_enter Put the host into maintenance mode. vim-cmd hostsvc/maintenance_mode_exit Take the host out of maintenance mode. vim-cmd hostsvc/net/info Show networking information of the host. chkconfig -l Show services running on the host. Can also be used to change startup configuration. esxtop Display list of processes and its usage of resources. Works similar to linux top. esxcfg-info Show host's configuration and information. esxcfg-nics -l Show current NIC configuration. esxcfg-vswitch -l Show current vSwitch configuration. vmkerrcode -l Display a reference list of VMKernel return codes and descriptions. dcui Start the console UI (when accessing through SSH). vsish Run the VMWare Interactive Shell (from SSH). decodeSel /var/log/ipmi_sel.raw Read IPMI system log of physical server. Replace vmid with the value you retrieved from the getallvms command (first one in the table).Replace path with the full path and file name of a VMX-file (= configuration file of a VM).","title":"Most common CLI commands for VMWare ESXi."},{"location":"security/openssl/","text":"Openssl Some stuff I came across while using openssl How to get a common name from an SSL certificate openssl x509 -noout -subject -in <path to cert> It will work with .pem etc.","title":"openssl"},{"location":"security/openssl/#openssl","text":"Some stuff I came across while using openssl","title":"Openssl"},{"location":"security/openssl/#how-to-get-a-common-name-from-an-ssl-certificate","text":"openssl x509 -noout -subject -in <path to cert> It will work with .pem etc.","title":"How to get a common name from an SSL certificate"},{"location":"windows/windows/","text":"RDP intermittantly freezes reg add \"HKLM\\software\\policies\\microsoft\\windows nt\\Terminal Services\\Client\" /v fClientDisableUDP /d 1 /t REG_DWORD","title":"RDP"},{"location":"windows/windows/#rdp-intermittantly-freezes","text":"reg add \"HKLM\\software\\policies\\microsoft\\windows nt\\Terminal Services\\Client\" /v fClientDisableUDP /d 1 /t REG_DWORD","title":"RDP intermittantly freezes"},{"location":"windows/wsl/","text":"WSL - Windows Linux Subsystem Some tips etc on how to use Windows WSL. Stop resolv.conf updating with local DNS If there is an issue connecting to some stuff defined in your WSL it is most likely DNS. To stop auto generation of resolv.conf you need to create a file /etc/wsl.conf and add the following, [network] generateResolvConf = false Then in a windows cmd line session, wsl --shutdown This shuts down wsl properly and saves any changes. How to import and export WSL distros Distros already installed and up to date from MS Store. Import a WSL distro Open cmd prompt as admin. wsl --list --all This will list all the WSL distros on your computer. To import, wsl --import <Name of distro> <path to save the <backupname>.tar filename Export a WSL distro Open cmd prompt as admin. wsl --list --all Pick your distro for export. wsl --export <Name of distro> <name of export>.tar file to export to To Uninstall imported WSL distros wsl --list --all Pick your distro wsl --unregister <Name of distro> And thats it. Fix issues with Github or SSH issues Modify the .bashrc file on the end with this, eval $(ssh-agent -s) && ssh-add ~/.ssh/<private key name> Obviously you can use an absolute path to point to wherever you store private keys you want to use when accessing remote hosts using ssh authentication with keys.","title":"WSL"},{"location":"windows/wsl/#wsl-windows-linux-subsystem","text":"Some tips etc on how to use Windows WSL.","title":"WSL - Windows Linux Subsystem"},{"location":"windows/wsl/#stop-resolvconf-updating-with-local-dns","text":"If there is an issue connecting to some stuff defined in your WSL it is most likely DNS. To stop auto generation of resolv.conf you need to create a file /etc/wsl.conf and add the following, [network] generateResolvConf = false Then in a windows cmd line session, wsl --shutdown This shuts down wsl properly and saves any changes.","title":"Stop resolv.conf updating with local DNS"},{"location":"windows/wsl/#how-to-import-and-export-wsl-distros","text":"Distros already installed and up to date from MS Store.","title":"How to import and export WSL distros"},{"location":"windows/wsl/#import-a-wsl-distro","text":"Open cmd prompt as admin. wsl --list --all This will list all the WSL distros on your computer. To import, wsl --import <Name of distro> <path to save the <backupname>.tar filename","title":"Import a WSL distro"},{"location":"windows/wsl/#export-a-wsl-distro","text":"Open cmd prompt as admin. wsl --list --all Pick your distro for export. wsl --export <Name of distro> <name of export>.tar file to export to","title":"Export a WSL distro"},{"location":"windows/wsl/#to-uninstall-imported-wsl-distros","text":"wsl --list --all Pick your distro wsl --unregister <Name of distro> And thats it.","title":"To Uninstall imported WSL distros"},{"location":"windows/wsl/#fix-issues-with-github-or-ssh-issues","text":"Modify the .bashrc file on the end with this, eval $(ssh-agent -s) && ssh-add ~/.ssh/<private key name> Obviously you can use an absolute path to point to wherever you store private keys you want to use when accessing remote hosts using ssh authentication with keys.","title":"Fix issues with Github or SSH issues"}]}